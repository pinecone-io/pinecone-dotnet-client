types:
  EmbedRequestParameters:
    docs: Model-specific parameters.
    properties:
      input_type:
        type: optional<string>
        docs: Common property used to distinguish between types of data.
      truncate:
        type: optional<string>
        docs: >
          How to handle inputs longer than those supported by the model. If
          `"END"`, truncate the input sequence at the token limit. If `"NONE"`,
          return an error when the input exceeds the token limit. 
        default: END
    source:
      openapi: ../inference/openapi/openapi.yml
    inline: true
  EmbedRequestInputsItem:
    properties:
      text: optional<string>
    source:
      openapi: ../inference/openapi/openapi.yml
    inline: true
imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    embed:
      path: /embed
      method: POST
      auth: true
      docs: >-
        Generate embeddings for input data.


        For guidance and examples, see [Generate
        embeddings](https://docs.pinecone.io/guides/inference/generate-embeddings).
      source:
        openapi: ../inference/openapi/openapi.yml
      display-name: Embed data
      request:
        name: EmbedRequest
        body:
          properties:
            model:
              type: string
              docs: >-
                The
                [model](https://docs.pinecone.io/guides/inference/understanding-inference#models)
                to use for embedding generation.
            parameters:
              type: optional<EmbedRequestParameters>
              docs: Model-specific parameters.
            inputs:
              docs: List of inputs to generate embeddings for.
              type: list<EmbedRequestInputsItem>
        content-type: application/json
      response:
        docs: OK
        type: root.EmbeddingsList
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.InternalServerError
      examples:
        - request:
            model: multilingual-e5-large
            inputs:
              - {}
          response:
            body:
              model: multilingual-e5-large
              data:
                - values:
                    - 0.1
                    - 0.2
                    - 0.3
              usage:
                total_tokens: 205
    rerank:
      path: /rerank
      method: POST
      auth: true
      docs: >-
        Rerank items according to their relevance to a query.


        For guidance and examples, see [Rerank
        documents](https://docs.pinecone.io/guides/inference/rerank).
      source:
        openapi: ../inference/openapi/openapi.yml
      display-name: Rerank items
      request:
        name: RerankRequest
        body:
          properties:
            model:
              type: string
              docs: >-
                The
                [model](https://docs.pinecone.io/guides/inference/understanding-inference#models)
                to use for reranking.
            query:
              type: string
              docs: The query to rerank documents against.
            top_n:
              type: optional<integer>
              docs: >-
                The number of results to return sorted by relevance. Defaults to
                the number of inputs.
            return_documents:
              type: optional<boolean>
              docs: Whether to return the documents in the response.
              default: true
            rank_fields:
              type: optional<list<string>>
              docs: >
                The fields to rank the documents by. If not provided, the
                default is `"text"`.
            documents:
              docs: The documents to rerank.
              type: list<root.Document>
            parameters:
              type: optional<map<string, string>>
              docs: Additional model-specific parameters for the reranker.
        content-type: application/json
      response:
        docs: OK
        type: root.RerankResult
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.InternalServerError
      examples:
        - request:
            model: bge-reranker-v2-m3
            query: What is the capital of France?
            documents:
              - id: '1'
                text: Paris is the capital of France.
                title: France
                url: https://example.com
          response:
            body:
              model: bge-reranker-v2-m3
              data:
                - index: 1
                  score: 0.5
                  document:
                    id: '1'
                    text: Paris is the capital of France.
                    title: France
                    url: https://example.com
              usage:
                rerank_units: 1
  source:
    openapi: ../inference/openapi/openapi.yml
  display-name: Inference
docs: Model inference
